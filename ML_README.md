# ğŸ¤– ML Module - Brain Tumor Segmentation

Bu modÃ¼l, beyin MR gÃ¶rÃ¼ntÃ¼lerinde tÃ¼mÃ¶r segmentasyonu iÃ§in U-Net tabanlÄ± derin Ã¶ÄŸrenme pipeline'Ä± iÃ§erir.

## ğŸ“‹ Ä°Ã§indekiler

- [Dosya YapÄ±sÄ±](#-dosya-yapÄ±sÄ±)
- [Kurulum](#-kurulum)
- [Veri HazÄ±rlama](#-veri-hazÄ±rlama)
- [Model EÄŸitimi](#-model-eÄŸitimi)
- [KonfigÃ¼rasyon](#-konfigÃ¼rasyon)
- [Model Mimarisi](#-model-mimarisi)
- [Utils ModÃ¼lleri](#-utils-modÃ¼lleri)
- [Model Export](#-model-export)
- [Sorun Giderme](#-sorun-giderme)

## ğŸ“ Dosya YapÄ±sÄ±

```
ml/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ train_unet.py           # Ana eÄŸitim scripti
â”‚   â”œâ”€â”€ check_gpu.py            # GPU kontrol scripti
â”‚   â”œâ”€â”€ config.yaml             # EÄŸitim konfigÃ¼rasyonu
â”‚   â”œâ”€â”€ inspect_h5.py           # H5 dosya inceleme
â”‚   â”œâ”€â”€ prepare_brats.py        # BraTS dataset hazÄ±rlama
â”‚   â”œâ”€â”€ prepare_h5_slices.py    # H5 slice hazÄ±rlama
â”‚   â”œâ”€â”€ prepare_png_dataset.py  # PNG dataset hazÄ±rlama
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ unet.py             # U-Net model tanÄ±mÄ±
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ data.py             # Veri pipeline (tf.data)
â”‚       â”œâ”€â”€ losses.py           # Custom loss fonksiyonlarÄ±
â”‚       â”œâ”€â”€ metrics.py          # Custom metrikler
â”‚       â””â”€â”€ exporter.py         # Model export (TFLite, ONNX)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ images/             # EÄŸitim gÃ¶rÃ¼ntÃ¼leri
â”‚   â”‚   â””â”€â”€ masks/              # EÄŸitim maskeleri
â”‚   â””â”€â”€ val/
â”‚       â”œâ”€â”€ images/             # Validation gÃ¶rÃ¼ntÃ¼leri
â”‚       â””â”€â”€ masks/              # Validation maskeleri
â”‚
â”œâ”€â”€ artifacts/                   # Model Ã§Ä±ktÄ±larÄ±
â”‚   â””â”€â”€ experiment_YYYYMMDD-HHMMSS/
â”‚       â”œâ”€â”€ config.yaml         # KullanÄ±lan konfigÃ¼rasyon
â”‚       â”œâ”€â”€ checkpoints/
â”‚       â”‚   â””â”€â”€ best.weights.h5 # En iyi model aÄŸÄ±rlÄ±klarÄ±
â”‚       â”œâ”€â”€ training_log.csv    # EÄŸitim loglarÄ±
â”‚       â”œâ”€â”€ tensorboard/        # TensorBoard loglarÄ±
â”‚       â”œâ”€â”€ model.tflite        # TFLite export
â”‚       â””â”€â”€ model.onnx          # ONNX export
â”‚
â”œâ”€â”€ prepare_dataset.py          # Dataset hazÄ±rlama scripti
â”œâ”€â”€ install_tensorflow_gpu.md   # GPU kurulum rehberi
â””â”€â”€ README.md
```

## ğŸ”§ Kurulum

### 1. Sanal Ortam

```bash
cd ml
python -m venv .venv
.venv\Scripts\activate  # Windows
pip install -r ../requirements.txt
```

### 2. GPU DesteÄŸi (Ã–nerilir)

```bash
# Conda ile CUDA kurulumu
conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0

# GPU kontrolÃ¼
python -m src.check_gpu
```

Beklenen Ã§Ä±ktÄ±:
```
[OK] 1 GPU bulundu ve yapÄ±landÄ±rÄ±ldÄ±:
   GPU 0: /physical_device:GPU:0
```

## ğŸ“Š Veri HazÄ±rlama

### Dataset YapÄ±sÄ±

Kaynak verinin aÅŸaÄŸÄ±daki yapÄ±da olmasÄ± gerekir:

```
source_folder/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ patient001_slice001.png
â”‚   â”œâ”€â”€ patient001_slice002.png
â”‚   â””â”€â”€ ...
â””â”€â”€ masks/
    â”œâ”€â”€ patient001_slice001.png  # AynÄ± isimle eÅŸleÅŸmeli
    â”œâ”€â”€ patient001_slice002.png
    â””â”€â”€ ...
```

### prepare_dataset.py KullanÄ±mÄ±

```bash
python prepare_dataset.py --source <kaynak_yolu> --target data --val-ratio 0.2 --seed 42
```

**Parametreler:**

| Parametre | VarsayÄ±lan | AÃ§Ä±klama |
|-----------|------------|----------|
| `--source` | - | Kaynak veri dizini (zorunlu) |
| `--target` | `ml/data` | Hedef dizin |
| `--val-ratio` | `0.2` | Validation split oranÄ± |
| `--seed` | `42` | Random seed |
| `--ext` | `png` | Dosya uzantÄ±larÄ± (virgÃ¼lle ayrÄ±lmÄ±ÅŸ) |

**Ã–rnek:**

```bash
python prepare_dataset.py \
    --source "C:\Users\tahak\Desktop\archive\brain_tumor" \
    --target data \
    --val-ratio 0.2 \
    --ext "png,jpg"
```

**Ã‡Ä±ktÄ±:**
```
Toplam Ã§iftler: 1000 | Train: 800 | Val: 200
Kopyalama tamamlandÄ±. Hedef: C:\Users\tahak\Desktop\BrSegmantion\ml\data
```

### BraTS Dataset HazÄ±rlama

NIfTI formatÄ±ndaki BraTS dataset iÃ§in:

```bash
python -m src.prepare_brats --input <brats_path> --output data
```

## ğŸš€ Model EÄŸitimi

### Temel KullanÄ±m

```bash
python -m src.train_unet --config src/config.yaml
```

### EÄŸitim AkÄ±ÅŸÄ±

1. **GPU KontrolÃ¼**: Mevcut GPU'lar tespit edilir ve memory growth aktifleÅŸtirilir
2. **Veri YÃ¼kleme**: `tf.data` pipeline ile verimli veri yÃ¼kleme
3. **Model OluÅŸturma**: U-Net mimarisi build edilir
4. **Callback HazÄ±rlÄ±ÄŸÄ±**: 
   - ModelCheckpoint (en iyi modeli kaydet)
   - CSVLogger (eÄŸitim loglarÄ±)
   - TensorBoard (gÃ¶rselleÅŸtirme)
   - ReduceLROnPlateau (learning rate scheduling)
   - EarlyStopping (erken durdurma)
5. **EÄŸitim**: Belirtilen epoch sayÄ±sÄ± kadar eÄŸitim
6. **Export**: TFLite ve/veya ONNX formatÄ±na dÃ¶nÃ¼ÅŸÃ¼m

### TensorBoard ile Ä°zleme

```bash
tensorboard --logdir artifacts
```

TarayÄ±cÄ±da http://localhost:6006 aÃ§Ä±n.

## âš™ï¸ KonfigÃ¼rasyon

### config.yaml YapÄ±sÄ±

```yaml
# Experiment tanÄ±mÄ±
experiment_name: "unet_brain_tumor"
seed: 42

# Veri yollarÄ±
paths:
  train_images: "data/train/images"
  train_masks: "data/train/masks"
  val_images: "data/val/images"
  val_masks: "data/val/masks"
  artifacts_dir: "artifacts"

# EÄŸitim parametreleri
training:
  img_size: 256           # GÃ¶rÃ¼ntÃ¼ boyutu (256x256)
  batch_size: 2           # Batch size (GPU memory'ye gÃ¶re ayarlayÄ±n)
  epochs: 100             # Maksimum epoch sayÄ±sÄ±
  learning_rate: 0.0001   # BaÅŸlangÄ±Ã§ learning rate
  optimizer: "adam"       # Optimizer (adam, sgd, rmsprop)
  loss: "bce_dice"        # Loss fonksiyonu (bce_dice, dice, binary_crossentropy)
  metrics:
    - "dice"              # DICE coefficient
    - "iou"               # IoU (Jaccard) score

# Data augmentation
augmentation:
  random_flip: true       # Yatay/dikey flip
  random_rotate: false    # 90Â° rotasyonlar
  random_zoom: false      # Zoom in/out
  zoom_scales: [0.9, 1.1] # Zoom aralÄ±ÄŸÄ±

# Model export
export:
  save_best_only: true    # Sadece en iyi modeli kaydet
  tflite: true            # TFLite export
  onnx: false             # ONNX export (tf2onnx gerektirir)
```

### Parametre Ã–nerileri

| Senaryo | batch_size | epochs | learning_rate |
|---------|------------|--------|---------------|
| HÄ±zlÄ± test | 8-16 | 10-20 | 0.001 |
| Normal eÄŸitim | 4-8 | 50-100 | 0.0001 |
| Fine-tuning | 2-4 | 20-50 | 0.00001 |
| BÃ¼yÃ¼k dataset | 16-32 | 100+ | 0.0001 |

## ğŸ—ï¸ Model Mimarisi

### U-Net DetaylarÄ±

```python
def build_unet(
    input_shape: Tuple[int, int, int] = (256, 256, 1),
    num_classes: int = 1,
    base_filters: int = 32,
    dropout: float = 0.1,
) -> keras.Model:
```

**Encoder BloÄŸu:**
```
Input â†’ Conv2D(3x3) â†’ BatchNorm â†’ ReLU â†’ Conv2D(3x3) â†’ BatchNorm â†’ ReLU â†’ MaxPool2D
```

**Decoder BloÄŸu:**
```
UpConv2D(2x2) â†’ Concat(skip_connection) â†’ Conv2D(3x3) â†’ BatchNorm â†’ ReLU â†’ Conv2D(3x3) â†’ BatchNorm â†’ ReLU
```

**Model Ã–zeti:**
```
Total params: ~1.9M (base_filters=32)
Trainable params: ~1.9M
Non-trainable params: 0
```

### Katman DetaylarÄ±

| Katman | Filtre | Ã‡Ä±ktÄ± Boyutu |
|--------|--------|--------------|
| enc1 | 32 | 256x256x32 |
| enc2 | 64 | 128x128x64 |
| enc3 | 128 | 64x64x128 |
| enc4 | 256 | 32x32x256 |
| bottleneck | 512 | 16x16x512 |
| dec1 | 256 | 32x32x256 |
| dec2 | 128 | 64x64x128 |
| dec3 | 64 | 128x128x64 |
| dec4 | 32 | 256x256x32 |
| output | 1 | 256x256x1 |

## ğŸ§° Utils ModÃ¼lleri

### data.py - Veri Pipeline

```python
def create_dataset(
    image_dir: str,
    mask_dir: str,
    img_size: int,
    batch_size: int,
    shuffle: bool = True,
    augment: bool = False,
    augmentation_config: dict = None,
    extensions: Iterable[str] = ("png", "jpg", "jpeg", "tif", "tiff"),
) -> tf.data.Dataset:
```

**Ã–zellikler:**
- Dosya ismine gÃ¶re otomatik image-mask eÅŸleÅŸtirme
- Lazy loading ile memory-efficient veri yÃ¼kleme
- Paralel veri iÅŸleme (`tf.data.AUTOTUNE`)
- Configurable augmentation

**Desteklenen Augmentasyonlar:**
- `random_flip`: Yatay ve dikey flip
- `random_rotate`: 90Â° rotasyonlar (0Â°, 90Â°, 180Â°, 270Â°)
- `random_zoom`: Scale faktÃ¶rÃ¼ ile zoom

### losses.py - Loss FonksiyonlarÄ±

```python
# Dice Loss
def dice_loss(y_true, y_pred, smooth=1e-6):
    """1 - DICE coefficient"""
    
# BCE + Dice Loss (Ã¶nerilen)
def bce_dice_loss(y_true, y_pred):
    """Binary Cross Entropy + Dice Loss kombinasyonu"""
```

**Loss SeÃ§imi:**
- `bce_dice`: Dengeli sonuÃ§lar iÃ§in (Ã¶nerilen)
- `dice`: Sadece overlap optimizasyonu
- `binary_crossentropy`: Standart BCE

### metrics.py - Metrikler

```python
# DICE Coefficient
def dice_coefficient(y_true, y_pred, smooth=1e-6):
    """2 * |A âˆ© B| / (|A| + |B|)"""
    
# IoU Score
def iou_score(y_true, y_pred, smooth=1e-6):
    """|A âˆ© B| / |A âˆª B|"""
```

### exporter.py - Model Export

```python
# TensorFlow Lite
def export_tflite(model: tf.keras.Model, export_path: Path) -> Path:
    """Keras modelini TFLite formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r"""

# ONNX
def export_onnx(model: tf.keras.Model, export_path: Path, opset: int = 13) -> Path:
    """Keras modelini ONNX formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r (tf2onnx gerektirir)"""
```

## ğŸ“¤ Model Export

### TFLite Export

Config'de aktifleÅŸtirin:
```yaml
export:
  tflite: true
```

veya manuel:
```python
from src.utils.exporter import export_tflite
export_tflite(model, Path("model.tflite"))
```

### ONNX Export

```bash
pip install tf2onnx
```

```yaml
export:
  onnx: true
```

## ğŸ” Sorun Giderme

### GPU AlgÄ±lanmÄ±yor

```bash
# GPU kontrolÃ¼
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"

# CUDA versiyon kontrolÃ¼
nvcc --version
```

**Ã‡Ã¶zÃ¼m:** CUDA 11.2 ve cuDNN 8.1 kurulu olduÄŸundan emin olun.

### Out of Memory (OOM)

**Ã‡Ã¶zÃ¼m:**
1. `batch_size` deÄŸerini dÃ¼ÅŸÃ¼rÃ¼n (2 veya 4)
2. `img_size` deÄŸerini dÃ¼ÅŸÃ¼rÃ¼n (128)
3. Memory growth aktif olduÄŸundan emin olun

### Veri EÅŸleÅŸme HatasÄ±

```
ValueError: EÅŸleÅŸen dosya bulunamadÄ±
```

**Ã‡Ã¶zÃ¼m:** 
- Image ve mask dosya isimlerinin aynÄ± olduÄŸundan emin olun
- UzantÄ±larÄ±n doÄŸru belirtildiÄŸini kontrol edin

### DÃ¼ÅŸÃ¼k DICE Score

**Ã‡Ã¶zÃ¼m:**
1. Daha fazla data augmentation ekleyin
2. Learning rate'i dÃ¼ÅŸÃ¼rÃ¼n
3. Daha fazla epoch eÄŸitin
4. Dropout oranÄ±nÄ± ayarlayÄ±n

## ğŸ“š Referanslar

- [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597)
- [TensorFlow Documentation](https://www.tensorflow.org/api_docs)
- [BraTS Challenge](https://www.med.upenn.edu/cbica/brats/)

---

ğŸ“ DetaylÄ± kullanÄ±m iÃ§in `config.yaml` dosyasÄ±nÄ± ve ana README'yi inceleyin.
